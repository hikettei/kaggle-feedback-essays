{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c895533e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T06:44:27.353263Z",
     "iopub.status.busy": "2022-03-08T06:44:27.351988Z",
     "iopub.status.idle": "2022-03-08T06:44:38.401546Z",
     "shell.execute_reply": "2022-03-08T06:44:38.400174Z",
     "shell.execute_reply.started": "2022-03-08T06:12:35.106514Z"
    },
    "papermill": {
     "duration": 11.066237,
     "end_time": "2022-03-08T06:44:38.401725",
     "exception": false,
     "start_time": "2022-03-08T06:44:27.335488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 06:44:27.989016: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2022-03-08 06:44:27.989142: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 06:44:32.738625: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-03-08 06:44:32.741465: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2022-03-08 06:44:32.741513: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-08 06:44:32.741540: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (4cae0eeb58a2): /proc/driver/nvidia/version does not exist\n",
      "2022-03-08 06:44:32.744341: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-08 06:44:32.745796: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-03-08 06:44:32.772065: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n",
      "2022-03-08 06:44:32.772115: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30021}\n",
      "2022-03-08 06:44:32.796370: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n",
      "2022-03-08 06:44:32.796426: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30021}\n",
      "2022-03-08 06:44:32.798247: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:30021\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import timeit\n",
    "\n",
    "# detect and init the TPU\n",
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "\n",
    "# instantiate a distribution strategy\n",
    "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "328b2852",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T06:44:38.434526Z",
     "iopub.status.busy": "2022-03-08T06:44:38.433795Z",
     "iopub.status.idle": "2022-03-08T06:45:33.958277Z",
     "shell.execute_reply": "2022-03-08T06:45:33.957682Z",
     "shell.execute_reply.started": "2022-03-08T06:12:40.398928Z"
    },
    "papermill": {
     "duration": 55.544617,
     "end_time": "2022-03-08T06:45:33.958427",
     "exception": false,
     "start_time": "2022-03-08T06:44:38.413810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15594/15594 [00:52<00:00, 298.40it/s]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(\"../input/feedback-prize-2021/\", \"train.csv\"))\n",
    "train[['discourse_id', 'discourse_start', 'discourse_end']] = train[['discourse_id', 'discourse_start', 'discourse_end']].astype(int)\n",
    "\n",
    "train[\"discourse_len\"] = train[\"discourse_text\"].apply(lambda x: len(x.split()))\n",
    "train[\"pred_len\"] = train[\"predictionstring\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "train_txt = glob.glob('../input/feedback-prize-2021/train/*.txt') \n",
    "\n",
    "cols_to_display = ['discourse_id', 'discourse_text', 'discourse_type','predictionstring', 'discourse_len', 'pred_len']\n",
    "train[cols_to_display].head()\n",
    "\n",
    "# this code chunk is copied from Rob Mulla\n",
    "len_dict = {}\n",
    "word_dict = {}\n",
    "for t in tqdm(train_txt):\n",
    "    with open(t, \"r\") as txt_file:\n",
    "        myid = t.split(\"/\")[-1].replace(\".txt\", \"\")\n",
    "        data = txt_file.read()\n",
    "        mylen = len(data.strip())\n",
    "        myword = len(data.split())\n",
    "        len_dict[myid] = mylen\n",
    "        word_dict[myid] = myword\n",
    "train[\"essay_len\"] = train[\"id\"].map(len_dict)\n",
    "train[\"essay_words\"] = train[\"id\"].map(word_dict)\n",
    "\n",
    "data_ids = train['id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a2daa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T06:45:34.300956Z",
     "iopub.status.busy": "2022-03-08T06:45:34.300253Z",
     "iopub.status.idle": "2022-03-08T06:46:06.822228Z",
     "shell.execute_reply": "2022-03-08T06:46:06.822731Z",
     "shell.execute_reply.started": "2022-03-08T06:13:39.145874Z"
    },
    "papermill": {
     "duration": 32.698731,
     "end_time": "2022-03-08T06:46:06.822900",
     "exception": false,
     "start_time": "2022-03-08T06:45:34.124169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144292/144292 [00:32<00:00, 4467.04it/s]\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>essay_len</th>\n",
       "      <th>gap_length</th>\n",
       "      <th>gap_end_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144270</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>0</td>\n",
       "      <td>317</td>\n",
       "      <td>Lead</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144271</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>318</td>\n",
       "      <td>515</td>\n",
       "      <td>Position</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144272</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>684</td>\n",
       "      <td>692</td>\n",
       "      <td>Claim</td>\n",
       "      <td>3140</td>\n",
       "      <td>167.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144273</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>693</td>\n",
       "      <td>710</td>\n",
       "      <td>Claim</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144274</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>714</td>\n",
       "      <td>724</td>\n",
       "      <td>Claim</td>\n",
       "      <td>3140</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144275</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>725</td>\n",
       "      <td>1360</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144276</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1361</td>\n",
       "      <td>1471</td>\n",
       "      <td>Claim</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144277</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1472</td>\n",
       "      <td>1881</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144278</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1882</td>\n",
       "      <td>2019</td>\n",
       "      <td>Claim</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144279</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>2029</td>\n",
       "      <td>2123</td>\n",
       "      <td>Claim</td>\n",
       "      <td>3140</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144280</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>2123</td>\n",
       "      <td>2702</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144281</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>2703</td>\n",
       "      <td>2799</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144282</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>2817</td>\n",
       "      <td>2907</td>\n",
       "      <td>Rebuttal</td>\n",
       "      <td>3140</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144283</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>2907</td>\n",
       "      <td>3140</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  discourse_start  discourse_end        discourse_type  \\\n",
       "144270  AFEC37C2D43F                0            317                  Lead   \n",
       "144271  AFEC37C2D43F              318            515              Position   \n",
       "144272  AFEC37C2D43F              684            692                 Claim   \n",
       "144273  AFEC37C2D43F              693            710                 Claim   \n",
       "144274  AFEC37C2D43F              714            724                 Claim   \n",
       "144275  AFEC37C2D43F              725           1360              Evidence   \n",
       "144276  AFEC37C2D43F             1361           1471                 Claim   \n",
       "144277  AFEC37C2D43F             1472           1881              Evidence   \n",
       "144278  AFEC37C2D43F             1882           2019                 Claim   \n",
       "144279  AFEC37C2D43F             2029           2123                 Claim   \n",
       "144280  AFEC37C2D43F             2123           2702              Evidence   \n",
       "144281  AFEC37C2D43F             2703           2799          Counterclaim   \n",
       "144282  AFEC37C2D43F             2817           2907              Rebuttal   \n",
       "144283  AFEC37C2D43F             2907           3140  Concluding Statement   \n",
       "\n",
       "        essay_len  gap_length  gap_end_length  \n",
       "144270       3140         NaN             NaN  \n",
       "144271       3140         NaN             NaN  \n",
       "144272       3140       167.0             NaN  \n",
       "144273       3140         NaN             NaN  \n",
       "144274       3140         2.0             NaN  \n",
       "144275       3140         NaN             NaN  \n",
       "144276       3140         NaN             NaN  \n",
       "144277       3140         NaN             NaN  \n",
       "144278       3140         NaN             NaN  \n",
       "144279       3140         8.0             NaN  \n",
       "144280       3140         NaN             NaN  \n",
       "144281       3140         NaN             NaN  \n",
       "144282       3140        16.0             NaN  \n",
       "144283       3140         NaN             NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize column\n",
    "train['gap_length'] = np.nan\n",
    "\n",
    "#set the first one\n",
    "train.loc[0, 'gap_length'] = 7 #discourse start - 1 (previous end is always -1)\n",
    "\n",
    "#loop over rest\n",
    "for i in tqdm(range(1, len(train))):\n",
    "    #gap if difference is not 1 within an essay\n",
    "    if ((train.loc[i, \"id\"] == train.loc[i-1, \"id\"])\\\n",
    "        and (train.loc[i, \"discourse_start\"] - train.loc[i-1, \"discourse_end\"] > 1)):\n",
    "        train.loc[i, 'gap_length'] = train.loc[i, \"discourse_start\"] - train.loc[i-1, \"discourse_end\"] - 2\n",
    "        #minus 2 as the previous end is always -1 and the previous start always +1\n",
    "    #gap if the first discourse of an new essay does not start at 0\n",
    "    elif ((train.loc[i, \"id\"] != train.loc[i-1, \"id\"])\\\n",
    "        and (train.loc[i, \"discourse_start\"] != 0)):\n",
    "        train.loc[i, 'gap_length'] = train.loc[i, \"discourse_start\"] -1\n",
    "\n",
    "\n",
    " #is there any text after the last discourse of an essay?\n",
    "last_ones = train.drop_duplicates(subset=\"id\", keep='last')\n",
    "last_ones['gap_end_length'] = np.where((last_ones.discourse_end < last_ones.essay_len),\\\n",
    "                                       (last_ones.essay_len - last_ones.discourse_end),\\\n",
    "                                       np.nan)\n",
    "\n",
    "cols_to_merge = ['id', 'discourse_id', 'gap_end_length']\n",
    "train = train.merge(last_ones[cols_to_merge], on = [\"id\", \"discourse_id\"], how = \"left\")\n",
    "\n",
    "#display an example\n",
    "cols_to_display = ['id', 'discourse_start', 'discourse_end', 'discourse_type', 'essay_len', 'gap_length', 'gap_end_length']\n",
    "train[cols_to_display].query('id == \"AFEC37C2D43F\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7829ea4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T06:46:07.338825Z",
     "iopub.status.busy": "2022-03-08T06:46:07.337772Z",
     "iopub.status.idle": "2022-03-08T06:46:07.354659Z",
     "shell.execute_reply": "2022-03-08T06:46:07.355255Z",
     "shell.execute_reply.started": "2022-03-08T06:14:37.609329Z"
    },
    "papermill": {
     "duration": 0.278676,
     "end_time": "2022-03-08T06:46:07.355437",
     "exception": false,
     "start_time": "2022-03-08T06:46:07.076761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_text_data(file_name):\n",
    "    with open(f\"../input/feedback-prize-2021/train/{file_name}.txt\") as f:\n",
    "        txt = f.read()\n",
    "    return [nltk.pos_tag(nltk.word_tokenize(parag)) for parag in re.split(\"\\n\\n\", txt)]\n",
    "\n",
    "def add_gap_rows(essay):\n",
    "    cols_to_keep = ['discourse_start', 'discourse_end', 'discourse_type', 'gap_length', 'gap_end_length']\n",
    "    df_essay = train.query('id == @essay')[cols_to_keep].reset_index(drop = True)\n",
    "\n",
    "    #index new row\n",
    "    insert_row = len(df_essay)\n",
    "   \n",
    "    for i in range(1, len(df_essay)):          \n",
    "        if df_essay.loc[i,\"gap_length\"] >0:\n",
    "            if i == 0:\n",
    "                start = 0 #as there is no i-1 for first row\n",
    "                end = df_essay.loc[0, 'discourse_start'] -1\n",
    "                disc_type = \"Nothing\"\n",
    "                gap_end = np.nan\n",
    "                gap = np.nan\n",
    "                df_essay.loc[insert_row] = [start, end, disc_type, gap, gap_end]\n",
    "                insert_row += 1\n",
    "            else:\n",
    "                start = df_essay.loc[i-1, \"discourse_end\"] + 1\n",
    "                end = df_essay.loc[i, 'discourse_start'] -1\n",
    "                disc_type = \"Nothing\"\n",
    "                gap_end = np.nan\n",
    "                gap = np.nan\n",
    "                df_essay.loc[insert_row] = [start, end, disc_type, gap, gap_end]\n",
    "                insert_row += 1\n",
    "    df_essay = df_essay.sort_values(by = \"discourse_start\").reset_index(drop=True)\n",
    "\n",
    "    #add gap at end\n",
    "    if df_essay.loc[(len(df_essay)-1),'gap_end_length'] > 0:\n",
    "        start = df_essay.loc[(len(df_essay)-1), \"discourse_end\"] + 1\n",
    "        end = start + df_essay.loc[(len(df_essay)-1), 'gap_end_length']\n",
    "        disc_type = \"Nothing\"\n",
    "        gap_end = np.nan\n",
    "        gap = np.nan\n",
    "        df_essay.loc[insert_row] = [start, end, disc_type, gap, gap_end]\n",
    "        \n",
    "    return(df_essay)\n",
    "\n",
    "def prepare_train_data(essay):\n",
    "    df_essay = add_gap_rows(essay)\n",
    "    #code from https://www.kaggle.com/odins0n/feedback-prize-eda, but adjusted to df_essay\n",
    "    essay_file = \"../input/feedback-prize-2021/train/\" + essay + \".txt\"\n",
    "    items = []\n",
    "    p = 0\n",
    "    with open(essay_file, 'r') as file: data = file.read()\n",
    "    \n",
    "    for i, row in df_essay.iterrows():\n",
    "        p = int(row['discourse_start'])\n",
    "        e = int(row['discourse_end'])\n",
    "        items.append([data[p:e], row['discourse_type']])\n",
    "\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cad2b0f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T06:46:07.874507Z",
     "iopub.status.busy": "2022-03-08T06:46:07.873509Z",
     "iopub.status.idle": "2022-03-08T06:46:08.811290Z",
     "shell.execute_reply": "2022-03-08T06:46:08.812014Z",
     "shell.execute_reply.started": "2022-03-08T06:22:45.606641Z"
    },
    "papermill": {
     "duration": 1.199199,
     "end_time": "2022-03-08T06:46:08.812207",
     "exception": false,
     "start_time": "2022-03-08T06:46:07.613008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Initialize tokenizer\n",
    "model_name = \"../input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased\"\n",
    "bert_tokenizer = transformers.BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "dtype_to_num = {\"Lead\":0,\n",
    "                \"Position\":1,\n",
    "                \"Claim\":2,\n",
    "                \"Counterclaim\":3,\n",
    "                \"Rebuttal\":4,\n",
    "                \"Evidence\":5,\n",
    "                \"Concluding Statement\":6,\n",
    "                \"Nothing\":7}\n",
    "\n",
    "num_to_dtype = {v: k for k, v in dtype_to_num.items()}\n",
    "\n",
    "num_class_type = 8\n",
    "\n",
    "BERT_MAX_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12c13e09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T06:46:09.331512Z",
     "iopub.status.busy": "2022-03-08T06:46:09.330541Z",
     "iopub.status.idle": "2022-03-08T06:46:09.340476Z",
     "shell.execute_reply": "2022-03-08T06:46:09.341073Z",
     "shell.execute_reply.started": "2022-03-08T06:30:19.280050Z"
    },
    "papermill": {
     "duration": 0.270795,
     "end_time": "2022-03-08T06:46:09.341243",
     "exception": false,
     "start_time": "2022-03-08T06:46:09.070448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collect_train_sets():\n",
    "    train_lines = []\n",
    "    train_labels = []\n",
    "\n",
    "    max_data_size = 6000\n",
    "    max_length    = 50\n",
    "    max_sentence_size = 0\n",
    "\n",
    "\n",
    "    for i in tqdm(range(max_data_size)):\n",
    "        for txt in prepare_train_data(data_ids[i]):\n",
    "            l = len(bert_tokenizer.tokenize(txt[0]))\n",
    "            if l <= max_length:\n",
    "                train_lines.append(txt[0])\n",
    "                train_labels.append(dtype_to_num[txt[1]])\n",
    "            else:\n",
    "                for t in re.split(\"[.?\\n]\", txt[0]):\n",
    "                    tsize = len(bert_tokenizer.tokenize(t))\n",
    "                    if tsize <= 100:\n",
    "                        max_sentence_size = max([max_sentence_size, tsize])\n",
    "                        train_lines.append(t)\n",
    "                        train_labels.append(dtype_to_num[txt[1]])\n",
    "                    else:\n",
    "                        for t1 in re.split(\"[,]\", t):\n",
    "                            max_sentence_size = max([max_sentence_size, len(bert_tokenizer.tokenize(t1))])\n",
    "                            train_lines.append(t1)\n",
    "                            train_labels.append(dtype_to_num[txt[1]])\n",
    "\n",
    "    max_length = max_sentence_size\n",
    "    print(max_length)\n",
    "    if max_length > BERT_MAX_LENGTH:\n",
    "        raise ValueError(\"Max_length exceeds 512\")\n",
    "    return [train_lines, train_labels, max_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35816dd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T06:46:09.857307Z",
     "iopub.status.busy": "2022-03-08T06:46:09.856247Z",
     "iopub.status.idle": "2022-03-08T06:46:10.062043Z",
     "shell.execute_reply": "2022-03-08T06:46:10.062568Z",
     "shell.execute_reply.started": "2022-03-08T06:27:57.384078Z"
    },
    "papermill": {
     "duration": 0.465685,
     "end_time": "2022-03-08T06:46:10.062739",
     "exception": false,
     "start_time": "2022-03-08T06:46:09.597054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               name       size\n",
      "0             train  115308934\n",
      "1         last_ones   15937203\n",
      "2         word_dict     589936\n",
      "3          len_dict     589936\n",
      "4         train_txt     133352\n",
      "..              ...        ...\n",
      "63                i         28\n",
      "64  BERT_MAX_LENGTH         28\n",
      "65         __spec__         16\n",
      "66      __package__         16\n",
      "67       __loader__         16\n",
      "\n",
      "[68 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "print(pd.DataFrame([[val for val in dir()], [sys.getsizeof(eval(val)) for val in dir()]],\n",
    "                   index=['name','size']).T.sort_values('size', ascending=False).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "658d7723",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T06:46:10.573643Z",
     "iopub.status.busy": "2022-03-08T06:46:10.572933Z",
     "iopub.status.idle": "2022-03-08T06:46:10.584382Z",
     "shell.execute_reply": "2022-03-08T06:46:10.585004Z",
     "shell.execute_reply.started": "2022-03-08T06:27:59.600093Z"
    },
    "papermill": {
     "duration": 0.268533,
     "end_time": "2022-03-08T06:46:10.585182",
     "exception": false,
     "start_time": "2022-03-08T06:46:10.316649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_train_data(datas):\n",
    "    shape = (len(datas), BERT_MAX_LENGTH)\n",
    "    \n",
    "    input_ids = np.zeros(shape, dtype=\"int32\")\n",
    "    attention_mask = np.zeros(shape, dtype=\"int32\")\n",
    "    token_type_ids = np.zeros(shape, dtype=\"int32\")\n",
    "    \n",
    "    for i, data in enumerate(datas):\n",
    "        encoded = bert_tokenizer.encode_plus(datas[i],\n",
    "                                             max_length=BERT_MAX_LENGTH,\n",
    "                                             pad_to_max_length=True,\n",
    "                                             truncation=True)\n",
    "        input_ids[i] = encoded[\"input_ids\"]\n",
    "        attention_mask[i] = encoded[\"attention_mask\"]\n",
    "        token_type_ids[i] = encoded[\"token_type_ids\"] \n",
    "    \n",
    "    return [input_ids, attention_mask, token_type_ids]\n",
    "\n",
    "def build_model():\n",
    "    input_shape = (BERT_MAX_LENGTH,)\n",
    "    \n",
    "    input_ids = tf.keras.layers.Input(input_shape, dtype=tf.int32)\n",
    "    attention_mask = tf.keras.layers.Input(input_shape, dtype=tf.int32)\n",
    "    token_type_ids = tf.keras.layers.Input(input_shape, dtype=tf.int32)\n",
    "    \n",
    "    bert_model = transformers.TFBertModel.from_pretrained(model_name)\n",
    "    \n",
    "    bert_output = bert_model(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        token_type_ids=token_type_ids\n",
    "    )\n",
    "\n",
    "    last_hidden_state = bert_output.last_hidden_state\n",
    "    pooler_output     = bert_output.pooler_output\n",
    "    \n",
    "    output = tf.keras.layers.Dense(num_class_type, activation=\"softmax\")(pooler_output)\n",
    "    model = tf.keras.Model(inputs=[input_ids, attention_mask, token_type_ids], outputs=[output])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "315ec866",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T06:46:11.103024Z",
     "iopub.status.busy": "2022-03-08T06:46:11.102300Z",
     "iopub.status.idle": "2022-03-08T06:46:11.104733Z",
     "shell.execute_reply": "2022-03-08T06:46:11.105218Z",
     "shell.execute_reply.started": "2022-03-08T06:28:02.888498Z"
    },
    "papermill": {
     "duration": 0.267051,
     "end_time": "2022-03-08T06:46:11.105381",
     "exception": false,
     "start_time": "2022-03-08T06:46:10.838330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_train(train_lines, train_labels):\n",
    "    batch_size = 256\n",
    "    epoch = 30\n",
    "\n",
    "    test_size = 15\n",
    "    train_line_size = len(train_lines)\n",
    "\n",
    "    X_train = make_train_data(train_lines[test_size:train_line_size])\n",
    "    Y_train = tf.keras.utils.to_categorical(train_labels[test_size:train_line_size], num_classes=num_class_type)\n",
    "\n",
    "    X_test  = make_train_data(train_lines[0:test_size])\n",
    "    Y_test  = tf.keras.utils.to_categorical(train_labels[0:test_size], num_classes=num_class_type)\n",
    "    \n",
    "    model = build_model()\n",
    "        \n",
    "    model.summary()\n",
    "    \n",
    "    model.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epoch)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b83026a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T06:46:11.618176Z",
     "iopub.status.busy": "2022-03-08T06:46:11.617516Z",
     "iopub.status.idle": "2022-03-08T09:36:40.482106Z",
     "shell.execute_reply": "2022-03-08T09:36:40.482715Z",
     "shell.execute_reply.started": "2022-03-07T09:21:16.272504Z"
    },
    "papermill": {
     "duration": 10229.122785,
     "end_time": "2022-03-08T09:36:40.482997",
     "exception": false,
     "start_time": "2022-03-08T06:46:11.360212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [04:25<00:00, 22.56it/s]\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ../input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at ../input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 8)            6152        tf_bert_model[0][1]              \n",
      "==================================================================================================\n",
      "Total params: 109,488,392\n",
      "Trainable params: 109,488,392\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "692/692 [==============================] - 450s 532ms/step - loss: 1.0805 - acc: 0.6561\n",
      "Epoch 2/30\n",
      "692/692 [==============================] - 321s 463ms/step - loss: 0.8286 - acc: 0.7357\n",
      "Epoch 3/30\n",
      "692/692 [==============================] - 321s 463ms/step - loss: 0.7506 - acc: 0.7615\n",
      "Epoch 4/30\n",
      "692/692 [==============================] - 321s 463ms/step - loss: 0.6595 - acc: 0.7925\n",
      "Epoch 5/30\n",
      "692/692 [==============================] - 321s 463ms/step - loss: 0.5633 - acc: 0.8232\n",
      "Epoch 6/30\n",
      "692/692 [==============================] - 321s 464ms/step - loss: 0.4785 - acc: 0.8521\n",
      "Epoch 7/30\n",
      "692/692 [==============================] - 321s 463ms/step - loss: 0.4137 - acc: 0.8742\n",
      "Epoch 8/30\n",
      "692/692 [==============================] - 321s 463ms/step - loss: 0.3645 - acc: 0.8901\n",
      "Epoch 9/30\n",
      "692/692 [==============================] - 321s 464ms/step - loss: 0.3361 - acc: 0.8996\n",
      "Epoch 10/30\n",
      "692/692 [==============================] - 321s 464ms/step - loss: 0.3142 - acc: 0.9063\n",
      "Epoch 11/30\n",
      "692/692 [==============================] - 321s 464ms/step - loss: 0.3000 - acc: 0.9105\n",
      "Epoch 12/30\n",
      "692/692 [==============================] - 321s 464ms/step - loss: 0.2911 - acc: 0.9142\n",
      "Epoch 13/30\n",
      "692/692 [==============================] - 321s 464ms/step - loss: 0.2853 - acc: 0.9155\n",
      "Epoch 14/30\n",
      "692/692 [==============================] - 321s 464ms/step - loss: 0.2855 - acc: 0.9155\n",
      "Epoch 15/30\n",
      "692/692 [==============================] - 321s 464ms/step - loss: 0.2755 - acc: 0.9190\n",
      "Epoch 16/30\n",
      "692/692 [==============================] - 321s 464ms/step - loss: 0.2724 - acc: 0.9198\n",
      "Epoch 17/30\n",
      "692/692 [==============================] - 321s 464ms/step - loss: 0.2680 - acc: 0.9216\n",
      "Epoch 18/30\n",
      "692/692 [==============================] - 321s 464ms/step - loss: 0.2679 - acc: 0.9220\n",
      "Epoch 19/30\n",
      "692/692 [==============================] - 321s 464ms/step - loss: 0.2660 - acc: 0.9218\n",
      "Epoch 20/30\n",
      "692/692 [==============================] - 321s 464ms/step - loss: 0.2621 - acc: 0.9239\n",
      "Epoch 21/30\n",
      "692/692 [==============================] - 321s 464ms/step - loss: 0.2631 - acc: 0.9234\n",
      "Epoch 22/30\n",
      "692/692 [==============================] - 321s 464ms/step - loss: 0.2594 - acc: 0.9246\n",
      "Epoch 23/30\n",
      "692/692 [==============================] - 321s 464ms/step - loss: 0.2595 - acc: 0.9240\n",
      "Epoch 24/30\n",
      "692/692 [==============================] - 321s 464ms/step - loss: 0.2620 - acc: 0.9233\n",
      "Epoch 25/30\n",
      "692/692 [==============================] - 321s 464ms/step - loss: 0.2603 - acc: 0.9242\n",
      "Epoch 26/30\n",
      "692/692 [==============================] - 321s 464ms/step - loss: 0.2576 - acc: 0.9247\n",
      "Epoch 27/30\n",
      "692/692 [==============================] - 321s 464ms/step - loss: 0.2547 - acc: 0.9255\n",
      "Epoch 28/30\n",
      "692/692 [==============================] - 321s 464ms/step - loss: 0.2539 - acc: 0.9263\n",
      "Epoch 29/30\n",
      "692/692 [==============================] - 321s 464ms/step - loss: 0.2552 - acc: 0.9254\n",
      "Epoch 30/30\n",
      "692/692 [==============================] - 321s 464ms/step - loss: 0.2509 - acc: 0.9265\n"
     ]
    }
   ],
   "source": [
    "train_lines, train_labels, max_length = collect_train_sets()\n",
    "with tpu_strategy.scope():\n",
    "    model = model_train(train_lines, train_labels)\n",
    "model.save_weights(\"./bert_trained_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff937f23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T09:36:55.355701Z",
     "iopub.status.busy": "2022-03-08T09:36:55.344125Z",
     "iopub.status.idle": "2022-03-08T09:37:17.236234Z",
     "shell.execute_reply": "2022-03-08T09:37:17.235630Z",
     "shell.execute_reply.started": "2022-03-07T13:55:45.677803Z"
    },
    "papermill": {
     "duration": 29.304442,
     "end_time": "2022-03-08T09:37:17.236390",
     "exception": false,
     "start_time": "2022-03-08T09:36:47.931948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>92 93 94 95 96 97 98 99 100 101 102 103 104 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>118 119 120 121 122 123 124 125 126 127 128 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>D46BCB48440A</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>335 336 337 338 339 340 341 342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>D46BCB48440A</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>345 346 347 348 349 350 351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>D46BCB48440A</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>352 353 354 355 356 357 358 359 360 361 362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>D46BCB48440A</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>395 396 397 398 399 400 401 402 403 404 405 40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>D46BCB48440A</td>\n",
       "      <td>Evidence</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id     class                                   predictionstring\n",
       "0    0FB0700DAF44  Evidence  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...\n",
       "1    0FB0700DAF44  Evidence  44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 5...\n",
       "2    0FB0700DAF44  Evidence  70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 8...\n",
       "3    0FB0700DAF44  Evidence  92 93 94 95 96 97 98 99 100 101 102 103 104 10...\n",
       "4    0FB0700DAF44  Evidence  118 119 120 121 122 123 124 125 126 127 128 12...\n",
       "..            ...       ...                                                ...\n",
       "129  D46BCB48440A  Evidence                    335 336 337 338 339 340 341 342\n",
       "130  D46BCB48440A  Evidence                        345 346 347 348 349 350 351\n",
       "131  D46BCB48440A  Evidence        352 353 354 355 356 357 358 359 360 361 362\n",
       "132  D46BCB48440A  Evidence  395 396 397 398 399 400 401 402 403 404 405 40...\n",
       "133  D46BCB48440A  Evidence                                                   \n",
       "\n",
       "[134 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_txt = glob.glob('../input/feedback-prize-2021/test/*.txt')\n",
    "sub = []\n",
    "\n",
    "for t in test_txt:\n",
    "    with open(t, \"r\") as txt_file:\n",
    "        myid          = t.split(\"/\")[-1].replace(\".txt\", \"\")\n",
    "        datas         = re.split(\"[.?\\n]\", txt_file.read())\n",
    "        input_X       = make_train_data(datas)\n",
    "        X_predict = model.predict(input_X)\n",
    "        X_predict_num = np.argmax(X_predict, axis=1)\n",
    "        p = 0\n",
    "        last_found_dtype = -1\n",
    "        last_word_list   = []\n",
    "        for i, data in enumerate(datas):\n",
    "            if len(data) == 0:\n",
    "                p += 1\n",
    "            else:\n",
    "                word_count = len(bert_tokenizer.tokenize(data))\n",
    "                if X_predict_num[i] == 7:\n",
    "                    pass\n",
    "                else:\n",
    "                    word_list = [str(x) for x in range(p, p+word_count)]\n",
    "                    if last_found_dtype == X_predict_num[i]:\n",
    "                        last_word_list = last_word_list + word_list\n",
    "                        sub.append((myid, num_to_dtype[X_predict_num[i]], ' '.join(last_word_list)))\n",
    "                        last_word_list = []\n",
    "                    else:\n",
    "                        last_found_dtype = X_predict_num[i]\n",
    "                        last_word_list   = word_list\n",
    "                p += word_count\n",
    "                \n",
    "df = pd.DataFrame(sub)\n",
    "df.columns = ['id','class','predictionstring']\n",
    "df.to_csv('submission.csv',index=False)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10388.290181,
   "end_time": "2022-03-08T09:37:27.451966",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-08T06:44:19.161785",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
